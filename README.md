**HW3_Image Captioning using an LSTM Language Model**<br>
This project implements an image captioning model that generates natural language descriptions from image features. It uses a pre-trained CNN encoder to extract 512-dimensional image embeddings, which are concatenated with 512-dimensional word embeddings and passed into an LSTM network (input size 1024). The decoder is trained with teacher forcing and evaluated with both greedy decoding and beam search. Techniques include PyTorch Dataset design, sequence padding, tokenization, and dynamic caption generation. This project demonstrates the full pipeline of image-to-text modeling.

**HW4_Fine-Tuning BERT for Semantic Role Labeling**<br>
This project fine-tunes a BERT-based encoder for the task of Semantic Role Labeling (SRL). It uses the CoNLL-2005 dataset and aligns token-level BIO labels with BERT subword outputs using the HuggingFace Transformers library. The model adds a linear classifier on top of the BERT outputs and is trained with cross-entropy loss. Evaluation is done using F1 score and precision/recall metrics. The project includes data preprocessing, model fine-tuning, and detailed error analysis. It demonstrates practical skills in transfer learning and sequence labeling with BERT.
